{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In cultural matching, we want to find similarities between both, the job posing and the CV.\n",
    "\n",
    "> As one approach, we could treat the graph built as an indicator of it, by leaving the final user (recruiter) to tune each of the charcteristics.\n",
    "\n",
    "> But, considering that we would like to make this as simple as possible, as a first approach, then we can take both, job posting and CV, create somehow a note over the culture tree and compare both resulting marks of the two obtained marked trees.\n",
    "\n",
    "> This last approach, less user responsible is going to be taken.\n",
    "\n",
    "> We've observed thatn between the GloVe and Word2Vec algorihtms, GloVe seems to be a better fit since it can handle the antonyms' relationships well. As a directed tree, with each main node divided in antonym terms (binary definitions) the interest on well capturing the antonym nature of words is important.\n",
    "\n",
    "> As an exemple, we don't want \"centric\" and \"liberal\" terms to be directly associated, they may be related as the subject they speak about is the same but not in the meaning which is different. In word2vec we have a simality of 22%, instead, in gloVe we have a 2% similartity.\n",
    "\n",
    "\n",
    "***Phrases***\n",
    "\n",
    "> It' might be better idea to attack phrase per phrase instead of all the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://radimrehurek.com/gensim/models/deprecated/keyedvectors.html\n",
    "# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "# https://nlp.stanford.edu/projects/glove/\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Grab model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeporti/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "dim_n = 300\n",
    "glove_input_file = f'./data/glove.6B.{dim_n}d.txt'\n",
    "word2vec_output_file = f'./data/glove.6B.{dim_n}d.txt.word2vec'\n",
    "if not os.path.isfile(word2vec_output_file): \n",
    "    glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Treat a CV job description*** (by phrase/as a hole for power distance terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1 = ['collaborate', 'design', 'front', 'end', 'back', 'end', 'programming', 'teams', \n",
    "    'concept', 'build', 'test', 'launch', 'dynamic', 'websites', 'industry', 'best', 'practices']\n",
    "ph2 =['work', 'closely', 'other', 'web', 'developers', 'ensure',\n",
    "    'client',  'marketing', 'goals', 'objectives', 'understood', 'met', \n",
    "    'established', 'timelines', 'highest', 'level','quality']\n",
    "ph3 = ['expert', 'wordpress']\n",
    "ph4 = ['working', 'e-commerce', 'agile', 'environment']\n",
    "ph5 = ['coding', 'wordpress', 'environment', 'develop', 'update', 'code',\n",
    "       'themes', 'plugins']\n",
    "ph6 = ['modify', 'existing', 'code', 'needed']\n",
    "ph7 = ['coding', 'custom', 'wordpress', 'theme' , 'template', \n",
    "       'files', 'using']\n",
    "\n",
    "job_desc_list = [ph1, ph2, ph4, ph5, ph6, ph7]\n",
    "job_desc = [ e for l in job_desc_list for e in l ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48150490577046046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity(ph1, ['central', 'central', 'central', 'theme', 'theme', 'theme', 'theme', 'theme'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Questions to answer***\n",
    "1. Is it better to take just the main term to give a mark of the characteristic studied? Or, is it convinient to take into account the whole terms defining the main term?\n",
    "2. Is it better to insert all descriptions or description by description or phrase by phrase by description?\n",
    "3. Maybe repetition of one word could be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decentralized\n",
      "ALL_List: --->  0.629349730778717\n",
      "ALL_Mix: ---->  0.6148914382982402\n",
      "centralized\n",
      "ALL_List: --->  0.6258741336624906\n",
      "ALL_Mix: ---->  0.618690927101161\n",
      "experience_based\n",
      "ALL_List: --->  0.6338805384593375\n",
      "ALL_Mix: ---->  0.6754670508805974\n",
      "rule_based\n",
      "ALL_List: --->  0.5376641312493753\n",
      "ALL_Mix: ---->  0.5867767524773739\n",
      "proactive\n",
      "ALL_List: --->  0.28905265306172173\n",
      "ALL_Mix: ---->  0.43604826584802026\n",
      "needy\n",
      "ALL_List: --->  0.022061951883183942\n",
      "ALL_Mix: ---->  0.23779175944909206\n",
      "emotional\n",
      "ALL_List: --->  0.4201617339640699\n",
      "ALL_Mix: ---->  0.4471875470790387\n",
      "pragmatic\n",
      "ALL_List: --->  0.6042256129991649\n",
      "ALL_Mix: ---->  0.6055872682141078\n"
     ]
    }
   ],
   "source": [
    "_repetitive = ['structure', 'organization', 'organizational', 'structure']\n",
    "ter_cen = [ 'boss', 'slow', 'decision-making', 'bureaucracy', 'promotion', 'hierarchy',\n",
    "            'functional', 'centralized', 'vertical',\n",
    "           ] +_repetitive\n",
    "ter_dec = [ 'disperse', 'leader', 'small', 'horizontal', 'organic', 'simple', 'decentralized'\n",
    "          ]+_repetitive\n",
    "ter_mix = [ 'hybrid', 'mixed', 'matrix'\n",
    "          ]+_repetitive\n",
    "# management\n",
    "# https://www.managementstudyguide.com/management-style.htm\n",
    "ter_man_experience_based = [ 'know-how', 'action', 'contact', 'involvement', 'participation', 'maturity', 'experience', 'democratic', \n",
    "    'laissez-faire', 'based'\n",
    "    ]\n",
    "ter_man_rule_based = [ 'guideline', 'manual', 'decree', 'order', 'regulation', 'norm', 'rule', 'boss', \n",
    "    'paternalistic', 'autocratic', 'based'\n",
    "    ]\n",
    "# member type\n",
    "ter_mem_proactive = [ 'proactive', 'propose', 'enthusiastic', 'energetic', 'spirited', 'passionate' ]\n",
    "ter_mem_order_needy = [ 'retroactive', 'reactive', 'careless', 'stative', 'shortsighted', 'needy' ]\n",
    "# Subordinate - superior relationship type\n",
    "# /!\\ not to include maybe, issue: terms need of context because they could refer tho other things\n",
    "ter_rel_pragmatic = [ 'pragmatic', 'practical', 'logical', 'efficient', 'realistic', \n",
    "    'feedback', 'relationship'\n",
    "    ] \n",
    "ter_rel_emotional = [ 'affecting', 'exciting', 'passionate', 'sentimental', 'spontaneous', \n",
    "    'critics', 'relationship'\n",
    "    ]\n",
    "\n",
    "power_dist = {\n",
    "    'centralized': {\n",
    "        'decentralized': ter_dec, \n",
    "        'centralized': ter_cen, \n",
    "        #'mixed': ter_mix\n",
    "    },\n",
    "    'management': {\n",
    "        'experience_based': ter_man_experience_based, \n",
    "        'rule_based': ter_man_rule_based\n",
    "    },\n",
    "    'member_type': {\n",
    "        'proactive': ter_mem_proactive,\n",
    "        'needy': ter_mem_order_needy\n",
    "    },\n",
    "    'subordinate_superior_relationship': {\n",
    "        'pragmatic': ter_rel_pragmatic,\n",
    "        'emotional': ter_rel_emotional,\n",
    "    }\n",
    "}\n",
    "\n",
    "job_desc = list(set(job_desc))\n",
    "\n",
    "for main_term, subs in power_dist.items():\n",
    "    for sub_term, l in subs.items():\n",
    "        sub_term_list = sub_term.split('_')\n",
    "        l_plus_terms = l + sub_term_list + main_term.split('_')\n",
    "        l_plus_terms = list(set(l_plus_terms)) #remove duplicates\n",
    "        print(sub_term)\n",
    "        #print(l_plus_terms)\n",
    "        #print(f'TERM: -->  { model.n_similarity(sub_term_list, job_desc) }')\n",
    "        print(f'ALL_List: --->  { model.n_similarity(l, job_desc) }')\n",
    "        print(f'ALL_Mix: ---->  { model.n_similarity(l_plus_terms, job_desc) }')\n",
    "        \"\"\"for phrase in job_desc_list:\n",
    "            print(f' {main_term}/LIST --------> { model.n_similarity(l, phrase) }')\n",
    "            print(f' {main_term}/LISTALL -----> { model.n_similarity(l_plus_terms, phrase) }')\"\"\"\n",
    "            #print(f' {main_term}/{sub_term} --> { model.n_similarity(sub_term_list, phrase) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centralized\n",
      "[('concept', 0.48), ('level', 0.47), ('design', 0.46), ('dynamic', 0.44), ('existing', 0.43), ('practices', 0.41), ('ensure', 0.41), ('develop', 0.41), ('work', 0.41), ('needed', 0.41)]\n",
      "0.2817307692307694\n",
      "decentralized\n",
      "[('using', 0.5), ('concept', 0.47), ('design', 0.47), ('build', 0.46), ('existing', 0.45), ('needed', 0.44), ('develop', 0.43), ('dynamic', 0.43), ('other', 0.42), ('work', 0.42)]\n",
      "0.28519230769230763\n",
      "mixed\n",
      "[('concept', 0.57), ('existing', 0.49), ('design', 0.49), ('dynamic', 0.47), ('using', 0.44), ('level', 0.43), ('develop', 0.42), ('build', 0.42), ('established', 0.41), ('quality', 0.41)]\n",
      "0.2857692307692307\n",
      "experience_based\n",
      "[('ensure', 0.48), ('concept', 0.48), ('other', 0.47), ('level', 0.46), ('develop', 0.45), ('needed', 0.45), ('work', 0.44), ('practices', 0.43), ('working', 0.42), ('environment', 0.41)]\n",
      "0.2874999999999999\n",
      "rule_based\n",
      "[('practices', 0.49), ('ensure', 0.42), ('code', 0.41), ('established', 0.41), ('existing', 0.41), ('concept', 0.4), ('using', 0.38), ('end', 0.37), ('work', 0.36), ('working', 0.36)]\n",
      "0.2428846153846154\n",
      "proactive\n",
      "[('dynamic', 0.37), ('agile', 0.34), ('environment', 0.28), ('work', 0.28), ('develop', 0.25), ('concept', 0.25), ('working', 0.25), ('themes', 0.22), ('needed', 0.22), ('build', 0.22)]\n",
      "0.1307692307692308\n",
      "needy\n",
      "[('modify', 0.23), ('agile', 0.23), ('timelines', 0.18), ('dynamic', 0.18), ('template', 0.14), ('plugins', 0.14), ('coding', 0.14), ('programming', 0.12), ('practices', 0.11), ('wordpress', 0.11)]\n",
      "0.007884615384615393\n",
      "pragmatic\n",
      "[('dynamic', 0.52), ('concept', 0.51), ('develop', 0.48), ('understood', 0.45), ('ensure', 0.43), ('work', 0.43), ('environment', 0.41), ('objectives', 0.41), ('needed', 0.41), ('design', 0.4)]\n",
      "0.2728846153846154\n",
      "emotional\n",
      "[('themes', 0.44), ('dynamic', 0.42), ('work', 0.4), ('understood', 0.4), ('best', 0.4), ('concept', 0.38), ('theme', 0.37), ('quality', 0.36), ('environment', 0.35), ('other', 0.33)]\n",
      "0.19096153846153857\n"
     ]
    }
   ],
   "source": [
    "similarities = {}\n",
    "for main_term, subs in power_dist.items():\n",
    "    for sub_term, l in subs.items():\n",
    "        sub_term_list = sub_term.split('_')\n",
    "        l_plus_terms = l + sub_term_list + main_term.split('_')\n",
    "        l_plus_terms = list(set(l_plus_terms)) #remove duplicates\n",
    "        l_plus_terms = l\n",
    "        for w in job_desc:\n",
    "            if main_term not in similarities: similarities[ main_term ] = {} \n",
    "            if sub_term not in similarities[ main_term ]: similarities[ main_term ][ sub_term ] = []\n",
    "            s = model.n_similarity([w], l_plus_terms)\n",
    "            similarities[ main_term ][ sub_term ].append((w, round(s, 2)))\n",
    "#similarities = sorted(similarities, key=itemgetter(1), reverse=True)\n",
    "for main_term, subs in similarities.items():\n",
    "    for sub_term, l in subs.items():\n",
    "        similarities[ main_term ][ sub_term ] = sorted(similarities[ main_term ][ sub_term ], key=itemgetter(1), reverse=True)\n",
    "        print(sub_term)\n",
    "        print(similarities[ main_term ][ sub_term ][:10])\n",
    "        long = len(similarities[ main_term ][ sub_term ])\n",
    "        print( sum( [e[1] for e in similarities[ main_term ][ sub_term ] ]) / long )\n",
    "#pp(similarities)\n",
    "a = ['concept','level','design','dynamic','practices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816043393940266"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity(job_desc, ['concept','level','design','dynamic','practices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The phrases may be compared to the list of terms defining one binary term since the cosine similarity would be better respresented.\n",
    "\n",
    "> The comparison of this list of terms, may be compared to the total bag of words. \n",
    "\n",
    "> Repetition in the calculation of cosine similarity does have an impact, so, repetition of words in the CV may be taken into account but avoid repetition in the terms to compare with. \n",
    "\n",
    "> Afterwards a measure by word could be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers as hp\n",
    "import data_extraction as de\n",
    "import lang_proc as lp\n",
    "import graph_treat as gt\n",
    "import importlib # importlib.reload(foo)\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb+srv://user_imt:2020@s5resumesdb-ppukj.azure.mongodb.net/test')\n",
    "db = client['db'] # db\n",
    "db_resumes = db['resumes'] #collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "resumes = db_resumes.find(limit=n)\n",
    "desc = de.buildDescriptionsList(resumes)\n",
    "description_list = hp.getValuesOfListOfDicts(desc, 'description')\n",
    "descriptions_string = hp.joinArrayOfStrings(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import json\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens, _ = lp.getFilteredTokensFromString(descriptions_string)\n",
    "f = open('./output/culture_graph.json')\n",
    "Gjson = json.load(f)\n",
    "G = nx.node_link_graph(Gjson)\n",
    "culture_terms = gt.getLeavesFromGraphImposingDistanceFromOrigin(G, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(decentralized_pd, 0.6134972760863979)\n",
      "(experience_based_pd, 0.6066947852415406)\n",
      "(proactive_pd, 0.24870041457317452)\n",
      "(pragmatic_rel_pd, 0.5599801664534805)\n",
      "----------\n",
      "(centralized_pd, 0.5865797388446993)\n",
      "(rule_based_pd, 0.5553802639809337)\n",
      "(order_needed_pd, 0.03563376642880263)\n",
      "(emotional_rel_pd, 0.38910159303892217)\n",
      "(small_power_distance, 50.72%) > (large_power_distance, 39.17 %)\n",
      "========================\n",
      "(group_int_pur_ic, 0.6038805352576356)\n",
      "(group_prom_based_ic, 0.6426414737361238)\n",
      "(moral_rel_ic, 0.4609301504591917)\n",
      "(indirect_comm_ic, 0.5881547556537802)\n",
      "----------\n",
      "(employer_int_pur_ic, 0.6743912126584001)\n",
      "(skills_performance_prom_based_ic, 0.6542291720671547)\n",
      "(contractual_rel_ic, 0.3194076569845463)\n",
      "(personal_comm_ic, 0.5454387035857609)\n",
      "(collectivist_culture, 57.39%) > (indivualist_culture, 54.84 %)\n",
      "========================\n",
      "(intuition_mgmt_mf, 0.38239420413397046)\n",
      "(negotiated_res_mf, 0.536212585302446)\n",
      "(equality_rew_mf, 0.3287735796965338)\n",
      "(work_to_live_mf, 0.2267525751484778)\n",
      "(leisure_over_money_mf, 0.32902547020516903)\n",
      "----------\n",
      "(decisive_mgmt_mf, 0.41394569202957854)\n",
      "(strongest_res_mf, 0.6773921294975064)\n",
      "(equity_rew_mf, 0.2512003487409247)\n",
      "(live_to_work_mf, 0.02043003733163422)\n",
      "(money_over_leisure_mf, 0.3738936712044237)\n",
      "(feminine_culture, 36.06%) > (masculine_culture, 34.74 %)\n",
      "========================\n",
      "(necessary_rules_ua, 0.5661755075481962)\n",
      "(work_on_need_ua, 0.6392242898887811)\n",
      "(time_as_orientation_ua, 0.4086157893706674)\n",
      "(ambiguity_tolerant_ua, 0.26217373163652785)\n",
      "(common_sense_approach_ua, 0.29192805516222387)\n",
      "(decision_process_ua, 0.7286663709112656)\n",
      "(entrepreneur_freedom_ua, 0.4102517281028017)\n",
      "(achievement_motivation_ua, 0.42856140967895884)\n",
      "----------\n",
      "(need_for_rules_ua, 0.5202846771975482)\n",
      "(workaholic_ua, 0.19243240772426112)\n",
      "(time_is_money_ua, 0.6695316607045433)\n",
      "(ambiguity_intolerant_ua, 0.4211345701260279)\n",
      "(technical_approach_ua, 0.5128334874252198)\n",
      "(decision_content_ua, 0.7518833296686677)\n",
      "(entrepreneur_framework_ua, 0.5832196751159194)\n",
      "(job_security_motivation_ua, 0.5781309018100994)\n",
      "(weak_uncertainty_avoidance, 46.69%) < (strong_uncertainty_avoidance, 52.87 %)\n",
      "========================\n",
      "(long_term_lt, 0.5798317532180312)\n",
      "----------\n",
      "(short_term_lt, 0.6182935901566499)\n",
      "(long_term_orientation, 57.98%) < (short_term_orientation, 61.83 %)\n",
      "========================\n",
      "(indulgence_ir, 0.40254963668803345)\n",
      "----------\n",
      "(restraint_ir, 0.4688068558564142)\n",
      "(indulgence, 40.25%) < (restraint, 46.88 %)\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "cv_terms, cv_not_found = hp.getItemsContainedInListAndNot(filtered_tokens, model.wv.vocab)\n",
    "culture_terms, _ = hp.getItemsContainedInListAndNot(culture_terms, model.wv.vocab)\n",
    "gt.calculateAllSimilaritiesFromListWithGraph(G, model, cv_terms, culture_terms, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(lp)\n",
    "n = 1\n",
    "jp = open(f'./data/job_post_rudresh/JobPost{n}')\n",
    "jp_string = jp.read()\n",
    "filtered_tokens_jp, _ = lp.getFilteredTokensFromString(jp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./output/culture_graph.json')\n",
    "Gjson = json.load(f)\n",
    "G_JP = nx.node_link_graph(Gjson)\n",
    "culture_terms = gt.getLeavesFromGraphImposingDistanceFromOrigin(G_JP, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(decentralized_pd, 0.6954599427786774)\n",
      "(experience_based_pd, 0.6621147196263707)\n",
      "(proactive_pd, 0.322707325780466)\n",
      "(pragmatic_rel_pd, 0.6678606387292925)\n",
      "----------\n",
      "(centralized_pd, 0.6489680606212184)\n",
      "(rule_based_pd, 0.49125592623180675)\n",
      "(order_needed_pd, 0.08892482163617417)\n",
      "(emotional_rel_pd, 0.4733779618257308)\n",
      "(small_power_distance, 58.7%) > (large_power_distance, 42.56 %)\n",
      "========================\n",
      "(group_int_pur_ic, 0.6425484736204766)\n",
      "(group_prom_based_ic, 0.6372173434386476)\n",
      "(moral_rel_ic, 0.5194921954615372)\n",
      "(indirect_comm_ic, 0.5469418151608537)\n",
      "----------\n",
      "(employer_int_pur_ic, 0.6588322280277823)\n",
      "(skills_performance_prom_based_ic, 0.6895893508488995)\n",
      "(contractual_rel_ic, 0.3132765421929119)\n",
      "(personal_comm_ic, 0.5856466540738643)\n",
      "(collectivist_culture, 58.65%) > (indivualist_culture, 56.18 %)\n",
      "========================\n",
      "(intuition_mgmt_mf, 0.5057330294622503)\n",
      "(negotiated_res_mf, 0.5107009137104368)\n",
      "(equality_rew_mf, 0.38810233379330955)\n",
      "(work_to_live_mf, 0.32401831505422285)\n",
      "(leisure_over_money_mf, 0.33620888079640476)\n",
      "----------\n",
      "(decisive_mgmt_mf, 0.46846613350767896)\n",
      "(strongest_res_mf, 0.6384758195802764)\n",
      "(equity_rew_mf, 0.26884517605977853)\n",
      "(live_to_work_mf, 0.0878057829058087)\n",
      "(money_over_leisure_mf, 0.40068104843608043)\n",
      "(feminine_culture, 41.3%) > (masculine_culture, 37.29 %)\n",
      "========================\n",
      "(necessary_rules_ua, 0.6292196203328371)\n",
      "(work_on_need_ua, 0.7067057214163384)\n",
      "(time_as_orientation_ua, 0.4717040252311651)\n",
      "(ambiguity_tolerant_ua, 0.3555046078644244)\n",
      "(common_sense_approach_ua, 0.43799625136238995)\n",
      "(decision_process_ua, 0.7234874753849373)\n",
      "(entrepreneur_freedom_ua, 0.5254228765962432)\n",
      "(achievement_motivation_ua, 0.5356725008914222)\n",
      "----------\n",
      "(need_for_rules_ua, 0.5615902478078008)\n",
      "(workaholic_ua, 0.28582570523704476)\n",
      "(time_is_money_ua, 0.6882161565881048)\n",
      "(ambiguity_intolerant_ua, 0.43367073920295784)\n",
      "(technical_approach_ua, 0.5975333428399507)\n",
      "(decision_content_ua, 0.7626572143635509)\n",
      "(entrepreneur_framework_ua, 0.6387850153128153)\n",
      "(job_security_motivation_ua, 0.5948347729882241)\n",
      "(weak_uncertainty_avoidance, 54.82%) < (strong_uncertainty_avoidance, 57.04 %)\n",
      "========================\n",
      "(long_term_lt, 0.6855139426812907)\n",
      "----------\n",
      "(short_term_lt, 0.6307979203380163)\n",
      "(long_term_orientation, 68.55%) > (short_term_orientation, 63.08 %)\n",
      "========================\n",
      "(indulgence_ir, 0.5147707143503361)\n",
      "----------\n",
      "(restraint_ir, 0.4623048540237493)\n",
      "(indulgence, 51.48%) > (restraint, 46.23 %)\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "jp_terms, jp_not_found = hp.getItemsContainedInListAndNot(filtered_tokens_jp, model.wv.vocab)\n",
    "culture_terms, _ = hp.getItemsContainedInListAndNot(culture_terms, model.wv.vocab)\n",
    "gt.calculateAllSimilaritiesFromListWithGraph(G_JP, model, jp_terms, culture_terms, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv_jp_processing as cvjp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lang_proc' from '/mnt/12564BAC564B8F81/code/learn/ps5/lang_proc.py'>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(de)\n",
    "importlib.reload(hp)\n",
    "importlib.reload(gt)\n",
    "importlib.reload(cvjp)\n",
    "importlib.reload(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = './output/culture_graph.json'\n",
    "n = 3\n",
    "jp_path = f'./data/job_post_rudresh/JobPost{n}'\n",
    "debug = False\n",
    "db_resumes = de.loadResumes()\n",
    "\n",
    "Gcv = gt.loadGraphFromFile(graph_path)\n",
    "Gjp = gt.loadGraphFromFile(graph_path)\n",
    "cv_string = de.getResumeString(db_resumes)\n",
    "jp_string = de.getJobPostingFromFile(jp_path)\n",
    "_ = cvjp.stringToCultureGraph(Gcv, model, cv_string, debug=debug)\n",
    "_ = cvjp.stringToCultureGraph(Gjp, model, jp_string, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5094630751917499, 0.3929205486433004, 0.5758724077842661, 0.5509700145409404, 0.3625913148157317, 0.34904399881068227, 0.46973353539980917, 0.5305938929771548, 0.5839265311096524, 0.6204785315635984, 0.4079614999559555, 0.4682582690329392]\n",
      "[0.5801543593394245, 0.42541745043647705, 0.6125616767343216, 0.5892072457563923, 0.40952124395180256, 0.3795523717117461, 0.5415123800923859, 0.5764545913347356, 0.7137206498838136, 0.6267456824083086, 0.4649594629440023, 0.5023939078466335]\n"
     ]
    }
   ],
   "source": [
    "dict_antonyms = gt.getTwoGraphsAttributeInfo(Gcv, Gjp, 6, 'similarity')\n",
    "cv_vec = [ t[0] for k, t in dict_antonyms.items() ]\n",
    "jp_vec = [ t[1] for k, t in dict_antonyms.items() ]\n",
    "print(cv_vec)\n",
    "print(jp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20137000750565187"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.euclidean_distance(cv_vec, jp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bita6748a10fd904a55b24d331e21814786"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
